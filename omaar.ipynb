{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from category_encoders import MEstimateEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos = pd.read_csv(\"auto_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The missing percentage of the dataset is 0.0858%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data Cleaning #\n",
    "# We will manipulate the missing data :\n",
    "missing = autos.isnull().sum()\n",
    "total_missing = missing.sum()\n",
    "# Calculating the percentage of missing data :\n",
    "total_cells = autos.shape[0]*autos.shape[1]\n",
    "missing_percentage = (total_missing/total_cells)*100\n",
    "print(\"The missing percentage of the dataset is {:.3}%\".format(missing_percentage))\n",
    "# As the missing percentage is very low so we will handle them by removing the columns that have the missing values\n",
    "autos_plus = autos.dropna(axis=1)\n",
    "# Two columns have been dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = autos_plus.copy()\n",
    "y = X.pop(\"price\")\n",
    "# Adding two new important columns :\n",
    "X[\"torque\"] = (X[\"horsepower\"] * 5252) / X[\"peak-rpm\"]\n",
    "X[\"speed\"] = (X[\"torque\"] * 1.35) / (X[\"curb-weight\"] / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_val_full, y_train, y_val = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_cardinality_columns = [col for col in X_train_full.columns\n",
    "                           if X_train_full[col].nunique() <= 10 and X_train_full[col].dtype == 'object']\n",
    "numerical_columns = [col for col in X_train_full.columns if X_train_full[col].dtype in ('float64', 'int64')]\n",
    "cols_needed = low_cardinality_columns + numerical_columns\n",
    "X_train = X_train_full[cols_needed].copy()\n",
    "X_val = X_val_full[cols_needed].copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot',OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num',numerical_transformer,numerical_columns),\n",
    "    ('cat',categorical_transformer,low_cardinality_columns)\n",
    "])\n",
    "mypipeline = Pipeline(steps=[\n",
    "    ('preprocessing',preprocessor),\n",
    "    ('modeling',RandomForestRegressor(n_estimators=100,random_state=0))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def baseline_scoring(X_train,y_train):\n",
    "    mypipeline.fit(X_train, y_train)\n",
    "    return mean_absolute_error(y_val,mypipeline.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_val(X,y):\n",
    "    scoring = -1*cross_val_score(mypipeline,X,y,\n",
    "                                 cv=100,\n",
    "                                 scoring='neg_mean_absolute_error')\n",
    "    return scoring.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding split\n",
    "X_encode = autos_plus.copy()\n",
    "y_encode = X_encode.pop('price')\n",
    "X_encode[\"torque\"] = (X_encode[\"horsepower\"] * 5252) / X_encode[\"peak-rpm\"]\n",
    "X_encode[\"speed\"] = (X_encode[\"torque\"] * 1.35) / (X_encode[\"curb-weight\"] / 1000)\n",
    "# Create an uninformative feature\n",
    "X_encode[\"Count\"] = range(len(X))\n",
    "X_encode[\"Count\"][1] = 0  # actually need one duplicate value to circumvent error-checking in MEstimateEncoder\n",
    "# Create the encoder instance. Choose m which is the smoothing factor to control noise.\n",
    "encoder = MEstimateEncoder(cols=[\"Count\"], m=0)\n",
    "# fit and transform on the same dataset\n",
    "X_encode = encoder.fit_transform(X_encode, y_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the baseline score will be 1551.9782520325207\n",
      "the score after the cross validation process will be 1613.344391666667\n",
      "The score after applying the target encoding with baseline scoring will be 557.2737804878049\n",
      "The score after applying the target encoding and cross validation will be 1613.344391666667\n"
     ]
    }
   ],
   "source": [
    "print(\"the baseline score will be {}\"\n",
    "      .format(baseline_scoring(X_train,y_train)))\n",
    "print(\"the score after the cross validation process will be {}\"\n",
    "      .format(cross_val(X,y)))\n",
    "print(\"The score after applying the target encoding with baseline scoring will be {}\"\n",
    "      .format(baseline_scoring(X_encode, y_encode)))\n",
    "print(\"The score after applying the target encoding and cross validation will be {}\"\n",
    "      .format(cross_val(X_encode, y_encode)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
